{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NA Filled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression AUC: 0.7234614169571523\n",
      "Best parameters for Logistic Regression: {'C': 100, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.scaler = None\n",
    "        \n",
    "    def normalize_data(self):\n",
    "        self.scaler = StandardScaler().fit(self.X_train)\n",
    "        self.X_train = self.scaler.transform(self.X_train)\n",
    "        self.X_test = self.scaler.transform(self.X_test)\n",
    "    \n",
    "    def feature_scaling(self):\n",
    "        self.scaler = MinMaxScaler().fit(self.X_train)\n",
    "        self.X_train = self.scaler.transform(self.X_train)\n",
    "        self.X_test = self.scaler.transform(self.X_test)\n",
    "    \n",
    "    def remove_outliers(self):\n",
    "        # Function to remove outliers using IQR\n",
    "        def remove_outliers_iqr(df):\n",
    "            numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "            parts = []\n",
    "            limit = 1000  # Limit of output rows\n",
    "            for col in df.columns:\n",
    "                if col.startswith('N'):\n",
    "                    q1 = df[col].quantile(0.25)\n",
    "                    q3 = df[col].quantile(0.75)\n",
    "                    iqr = q3 - q1\n",
    "                    lower_bound = q1 - 1.5 * iqr\n",
    "                    upper_bound = q3 + 1.5 * iqr\n",
    "                    part = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "                    if len(part) > limit:\n",
    "                        parts.append(part[:limit])\n",
    "                    else:\n",
    "                        parts.append(part)\n",
    "            return pd.concat(parts)\n",
    "\n",
    "        self.X_train = remove_outliers_iqr(self.X_train)\n",
    "        self.y_train = self.y_train.loc[self.X_train.index]\n",
    "    \n",
    "    def handle_imbalance(self):\n",
    "        smote = SMOTE(random_state=42)\n",
    "        self.X_train, self.y_train = smote.fit_resample(self.X_train, self.y_train)\n",
    "    \n",
    "    def logistic_regression(self):\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        params = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "        grid_search = GridSearchCV(model, params, cv=5, scoring='roc_auc')\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict_proba(self.X_test)[:, 1]\n",
    "        auc_score = roc_auc_score(self.y_test, y_pred)\n",
    "        return best_model, auc_score\n",
    "    \n",
    "    def svm(self):\n",
    "        model = SVC(probability=True)\n",
    "        params = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "        grid_search = GridSearchCV(model, params, cv=5, scoring='roc_auc')\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict_proba(self.X_test)[:, 1]\n",
    "        auc_score = roc_auc_score(self.y_test, y_pred)\n",
    "        return best_model, auc_score\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming you have X_train, X_test, y_train, y_test datasets available\n",
    "    # Perform data preprocessing steps\n",
    "\n",
    "    df = pd.read_csv('80%_null_drop_rest_filled.csv')\n",
    "    bool_map = {True : 1, False:0}\n",
    "    df['C6'] = df['C6'].map(bool_map)\n",
    "    df['C8'] = df['C8'].map(bool_map)\n",
    "\n",
    "    X = df.drop(['Unique_ID', 'Dependent_Variable'], axis = 1)\n",
    "    y = df['Dependent_Variable']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model_eval = ModelEvaluation(X_train, X_test, y_train, y_test)\n",
    "    model_eval.remove_outliers()\n",
    "    model_eval.handle_imbalance()\n",
    "    model_eval.normalize_data()  \n",
    "\n",
    "    # Logistic Regression\n",
    "    logistic_model, logistic_auc = model_eval.logistic_regression()\n",
    "    print(\"Logistic Regression AUC:\", logistic_auc)\n",
    "    print(\"Best parameters for Logistic Regression:\", logistic_model.get_params())\n",
    "\n",
    "    # SVM\n",
    "    svm_model, svm_auc = model_eval.svm()\n",
    "    print(\"SVM AUC:\", svm_auc)\n",
    "    print(\"Best parameters for SVM:\", svm_model.get_params())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputed NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelEvaluation:\n",
    "    def __init__(self, X_train, X_test, y_train, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.scaler = None\n",
    "        \n",
    "    def normalize_data(self):\n",
    "        self.scaler = StandardScaler().fit(self.X_train)\n",
    "        self.X_train = self.scaler.transform(self.X_train)\n",
    "        self.X_test = self.scaler.transform(self.X_test)\n",
    "    \n",
    "    def feature_scaling(self):\n",
    "        self.scaler = MinMaxScaler().fit(self.X_train)\n",
    "        self.X_train = self.scaler.transform(self.X_train)\n",
    "        self.X_test = self.scaler.transform(self.X_test)\n",
    "    \n",
    "    def remove_outliers(self):\n",
    "        # Function to remove outliers using IQR\n",
    "        def remove_outliers_iqr(df):\n",
    "            numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "            parts = []\n",
    "            limit = 1000  # Limit of output rows\n",
    "            for col in df.columns:\n",
    "                if col.startswith('N'):\n",
    "                    q1 = df[col].quantile(0.25)\n",
    "                    q3 = df[col].quantile(0.75)\n",
    "                    iqr = q3 - q1\n",
    "                    lower_bound = q1 - 1.5 * iqr\n",
    "                    upper_bound = q3 + 1.5 * iqr\n",
    "                    part = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "                    if len(part) > limit:\n",
    "                        parts.append(part[:limit])\n",
    "                    else:\n",
    "                        parts.append(part)\n",
    "            return pd.concat(parts)\n",
    "\n",
    "        self.X_train = remove_outliers_iqr(self.X_train)\n",
    "        self.y_train = self.y_train.loc[self.X_train.index]\n",
    "    \n",
    "    def handle_imbalance(self):\n",
    "        smote = SMOTE(random_state=42)\n",
    "        self.X_train, self.y_train = smote.fit_resample(self.X_train, self.y_train)\n",
    "    \n",
    "    def logistic_regression(self):\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        params = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "        grid_search = GridSearchCV(model, params, cv=5, scoring='roc_auc')\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict_proba(self.X_test)[:, 1]\n",
    "        auc_score = roc_auc_score(self.y_test, y_pred)\n",
    "        return best_model, auc_score\n",
    "    \n",
    "    def svm(self):\n",
    "        model = SVC(probability=True)\n",
    "        params = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "        grid_search = GridSearchCV(model, params, cv=5, scoring='roc_auc')\n",
    "        grid_search.fit(self.X_train, self.y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict_proba(self.X_test)[:, 1]\n",
    "        auc_score = roc_auc_score(self.y_test, y_pred)\n",
    "        return best_model, auc_score\n",
    "\n",
    "# Usage example:\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming you have X_train, X_test, y_train, y_test datasets available\n",
    "    # Perform data preprocessing steps\n",
    "\n",
    "    df = pd.read_csv('80%_null_drop_rest_impute_rf.csv')\n",
    "    bool_map = {True : 1, False:0}\n",
    "    df['C6'] = df['C6'].map(bool_map)\n",
    "    df['C8'] = df['C8'].map(bool_map)\n",
    "\n",
    "    X = df.drop(['Unique_ID', 'Dependent_Variable'], axis = 1)\n",
    "    y = df['Dependent_Variable']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model_eval = ModelEvaluation(X_train, X_test, y_train, y_test)\n",
    "    model_eval.remove_outliers()\n",
    "    model_eval.handle_imbalance()\n",
    "    model_eval.normalize_data()  \n",
    "\n",
    "    # Logistic Regression\n",
    "    logistic_model, logistic_auc = model_eval.logistic_regression()\n",
    "    print(\"Logistic Regression AUC:\", logistic_auc)\n",
    "    print(\"Best parameters for Logistic Regression:\", logistic_model.get_params())\n",
    "\n",
    "    # SVM\n",
    "    svm_model, svm_auc = model_eval.svm()\n",
    "    print(\"SVM AUC:\", svm_auc)\n",
    "    print(\"Best parameters for SVM:\", svm_model.get_params())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
